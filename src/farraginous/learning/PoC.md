---
date: 2024-04-08
category:
  - 学习
---

# 通信原理

## 1

信息量：$H=-log_2P(x)$ bit

信息熵（平均信息量）：$\sum -P(x_i)log_2P(x_i) \approx m\cdot H$ bit/symbol

信源符号等概时熵最大

$R_b = R_B \cdot H = R_B \cdot log_2M$（等概）

频带利用率：传输速率/带宽

误码率（码元） $P_e$ >= 误信率（bit） $P_b$ （二进制时相等）

## 2

自相关函数：反映不同时刻随机过程取值的相关性，$R(t_1,t_2)=E[\xi(t_{1})\xi(t_{2})]$

自协方差函数：反映不同时刻随机过程的统计相关性，$B(t_1,t_2)=E\{[\xi(t_{1})-a(t_{1})][\xi(t_{2})-a(t_{2})]\}$

广义平稳随机过程：均值为常数；自相关函数仅与时间间隔有关；$E(\xi^2(t))<+\infty$

维纳-辛钦定理：平稳随机过程，自相关函数$R(\tau)$ - 傅里叶变换 ->功率谱密度函数$P_\xi(\omega)$。

[平均功率两种计算方式](https://www.bilibili.com/video/BV1wA4y1f7Co/?p=5&t=1221)
