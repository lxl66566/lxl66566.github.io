import{_ as n,r as h,o,c as p,d as c,w as i,e as t,b as a,a as e}from"./app-8x5CEdJY.js";const d={},g=t('<h1 id="音频转文字" tabindex="-1"><a class="header-anchor" href="#音频转文字"><span>音频转文字</span></a></h1><p><strong>付费服务</strong>不在本文考虑范围内。</p><h2 id="移动端" tabindex="-1"><a class="header-anchor" href="#移动端"><span>移动端</span></a></h2><p>移动端自然不用多说，语音转文字但凡是个正常输入法都能干。对于中文，一般国产输入法的质量会好点，gboard 效果比较差。</p><p>录音转文字：</p><ul><li>小米的录音机能够转文字，不过效果较差，而且需要手动打标点。</li><li>一加的录音机更垃圾，我目前的 OS 版本必定 <code>转文本出现异常</code>。</li></ul><h2 id="桌面端" tabindex="-1"><a class="header-anchor" href="#桌面端"><span>桌面端</span></a></h2><h3 id="微软" tabindex="-1"><a class="header-anchor" href="#微软"><span>微软</span></a></h3><p>如果使用 windows 10/11，当然选择微软自家的语音输入，按 <code>Win + H</code> 即可（通过调输入法选择语言）。中文识别准确率在 2022 之前较一般，现在不错。</p><p>这里有一个 <a href="https://www.appinn.com/speech-to-text-windows10-and-11/" target="_blank" rel="noopener noreferrer">trick</a>，可以用微软语音转文字转音频。</p><h3 id="autosrt" tabindex="-1"><a class="header-anchor" href="#autosrt"><span>autosrt</span></a></h3><p>对于需要输入音频，输出 <strong>srt 字幕</strong>的场合，可以用 <a href="https://github.com/asukaminato0721/autosrt" target="_blank" rel="noopener noreferrer">autosrt</a> 跑本地模型。</p><ul><li>跨平台</li><li>多语言支持</li><li>使用纯 CPU，对内存要求不高</li><li>有很多模型可以选择，越大的模型自然越慢，需要平衡准确率与速度。参考我用 large 跑了个 30min 的中文字幕，在 laptop i5-12500 上跑了接近 1h。</li></ul><p>autosrt 在 linux 下是一个不错的选择。具体地：</p>',14),u=e("div",{class:"language-sh line-numbers-mode","data-highlighter":"shiki","data-ext":"sh","data-title":"sh",style:{"--shiki-light":"#24292e","--shiki-dark":"#abb2bf","--shiki-light-bg":"#fff","--shiki-dark-bg":"#282c34"}},[e("pre",{class:"shiki shiki-themes github-light one-dark-pro vp-code"},[e("code",null,[e("span",{class:"line"},[e("span",{style:{"--shiki-light":"#6F42C1","--shiki-dark":"#61AFEF"}},"paru"),e("span",{style:{"--shiki-light":"#005CC5","--shiki-dark":"#D19A66"}}," -S"),e("span",{style:{"--shiki-light":"#032F62","--shiki-dark":"#98C379"}}," whisper.cpp"),e("span",{style:{"--shiki-light":"#032F62","--shiki-dark":"#98C379"}}," ffmpeg"),e("span",{style:{"--shiki-light":"#6A737D","--shiki-dark":"#7F848E","--shiki-light-font-style":"inherit","--shiki-dark-font-style":"italic"}},"  # 可执行文件在 `/usr/bin/whisper.cpp`")]),a(`
`),e("span",{class:"line"},[e("span",{style:{"--shiki-light":"#6F42C1","--shiki-dark":"#61AFEF"}},"git"),e("span",{style:{"--shiki-light":"#032F62","--shiki-dark":"#98C379"}}," clone"),e("span",{style:{"--shiki-light":"#032F62","--shiki-dark":"#98C379"}}," git@github.com:lxl66566/autosrt.git")]),a(`
`),e("span",{class:"line"},[e("span",{style:{"--shiki-light":"#005CC5","--shiki-dark":"#56B6C2"}},"cd"),e("span",{style:{"--shiki-light":"#032F62","--shiki-dark":"#98C379"}}," autosrt"),e("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#ABB2BF"}}," && "),e("span",{style:{"--shiki-light":"#6F42C1","--shiki-dark":"#61AFEF"}},"python"),e("span",{style:{"--shiki-light":"#032F62","--shiki-dark":"#98C379"}}," main.py")])])]),e("div",{class:"line-numbers","aria-hidden":"true",style:{"counter-reset":"line-number 0"}},[e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"})])],-1),m=t('<p>然后遵循 readme，下载一个模型（我选择了 <code>ggml-small-q5_1</code> 181.3 MB），填入 GUI 即可。</p><h3 id="vscode" tabindex="-1"><a class="header-anchor" href="#vscode"><span>VSCode</span></a></h3><p>VSCode 居然支持语音输入了！(<a href="https://t.me/absxsgroup/6059" target="_blank" rel="noopener noreferrer">src</a>)这是我没想到的。你需要：</p><ol><li>安装插件 <em>VS Code Speech - Microsoft</em> 和 <em>Chinese (Simplified, China) language support for VS Code Speech - Microsoft</em></li><li>在设置中添加一行 <code>&quot;accessibility.voice.speechLanguage&quot;: &quot;zh-CN&quot;,</code></li></ol><p>实测识别准确率还是不错的。这下 Linux 也有即开即用的 voice2text 了，而且由于我本身就用 vscode 写日记，所以还挺好的。</p><p>不过有几个问题：</p><ol><li>不方便多语言切换，得去设置里改。</li><li>不支持 NixOS，因为 NixOS 不遵守 fhs，找不到 libasound。</li></ol><h3 id="capswriter" tabindex="-1"><a class="header-anchor" href="#capswriter"><span><a href="https://github.com/HaujetZhao/CapsWriter" target="_blank" rel="noopener noreferrer">CapsWriter</a></span></a></h3><p>一款语音输入工具，但是使用它需要购买阿里云的 API。因此不推荐。</p><h2 id="云端" tabindex="-1"><a class="header-anchor" href="#云端"><span>云端</span></a></h2><h3 id="腾讯云" tabindex="-1"><a class="header-anchor" href="#腾讯云"><span><a href="https://cloud.tencent.com/product/asr" target="_blank" rel="noopener noreferrer">腾讯云</a></span></a></h3><p>每月 10h 免费时长，基本够用。</p><p>懒得看文档了，左边有个 <em>功能体验</em>，上传录音，选择 <em>不带时间戳</em> 即可。</p><h3 id="whisper" tabindex="-1"><a class="header-anchor" href="#whisper"><span>whisper</span></a></h3><p>实际上上述 <a href="#autosrt">autosrt</a> 就是使用 whisper 模型放本地跑，只不过用 python 写了个小前端而已。在 huggingface 上也可以<a href="https://huggingface.co/spaces/sanchit-gandhi/whisper-jax" target="_blank" rel="noopener noreferrer">在线用</a>，不过速度比本地还要慢。（可以理解，又不是做慈善）</p><h4 id="whisper-jax" tabindex="-1"><a class="header-anchor" href="#whisper-jax"><span>whisper.jax</span></a></h4><p><a href="https://huggingface.co/spaces/sanchit-gandhi/whisper-jax" target="_blank" rel="noopener noreferrer">在线演示</a>，据说比 whisper 快 70 倍</p><h3 id="incredibly-fast-whisper" tabindex="-1"><a class="header-anchor" href="#incredibly-fast-whisper"><span>incredibly-fast-whisper</span></a></h3><p>基于 Whisper Large v3 模型。有一个<a href="https://replicate.com/vaibhavs10/incredibly-fast-whisper" target="_blank" rel="noopener noreferrer">在线 demo</a> 可以用。</p><h3 id="groq" tabindex="-1"><a class="header-anchor" href="#groq"><span><a href="https://console.groq.com/playground?model=whisper-large-v3-turbo" target="_blank" rel="noopener noreferrer">groq</a></span></a></h3><p>groq 有一定免费额度，是一个在线模型运行 playground。需要代理，不支持香港节点。</p>',21);function k(f,b){const r=h("CodeTabs");return o(),p("div",null,[g,c(r,{id:"70",data:[{id:"archlinux"}]},{title0:i(({value:s,isActive:l})=>[a("archlinux")]),tab0:i(({value:s,isActive:l})=>[u]),_:1}),m])}const y=n(d,[["render",k],["__file","voice2text.html.vue"]]),v=JSON.parse('{"path":"/articles/voice2text.html","title":"音频转文字","lang":"zh-CN","frontmatter":{"date":"2023-11-05T00:00:00.000Z","icon":"file-audio","category":["推荐","评价"],"tag":["横评"],"description":"音频转文字 付费服务不在本文考虑范围内。 移动端 移动端自然不用多说，语音转文字但凡是个正常输入法都能干。对于中文，一般国产输入法的质量会好点，gboard 效果比较差。 录音转文字： 小米的录音机能够转文字，不过效果较差，而且需要手动打标点。 一加的录音机更垃圾，我目前的 OS 版本必定 转文本出现异常。 桌面端 微软 如果使用 windows 10...","head":[["meta",{"property":"og:url","content":"https://absx.pages.dev/articles/voice2text.html"}],["meta",{"property":"og:site_name","content":"绝对值_x的博客"}],["meta",{"property":"og:title","content":"音频转文字"}],["meta",{"property":"og:description","content":"音频转文字 付费服务不在本文考虑范围内。 移动端 移动端自然不用多说，语音转文字但凡是个正常输入法都能干。对于中文，一般国产输入法的质量会好点，gboard 效果比较差。 录音转文字： 小米的录音机能够转文字，不过效果较差，而且需要手动打标点。 一加的录音机更垃圾，我目前的 OS 版本必定 转文本出现异常。 桌面端 微软 如果使用 windows 10..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-10-16T16:54:09.000Z"}],["meta",{"property":"article:tag","content":"横评"}],["meta",{"property":"article:published_time","content":"2023-11-05T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2024-10-16T16:54:09.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"音频转文字\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2023-11-05T00:00:00.000Z\\",\\"dateModified\\":\\"2024-10-16T16:54:09.000Z\\",\\"author\\":[]}"]]},"headers":[{"level":2,"title":"移动端","slug":"移动端","link":"#移动端","children":[]},{"level":2,"title":"桌面端","slug":"桌面端","link":"#桌面端","children":[{"level":3,"title":"微软","slug":"微软","link":"#微软","children":[]},{"level":3,"title":"autosrt","slug":"autosrt","link":"#autosrt","children":[]},{"level":3,"title":"VSCode","slug":"vscode","link":"#vscode","children":[]},{"level":3,"title":"CapsWriter","slug":"capswriter","link":"#capswriter","children":[]}]},{"level":2,"title":"云端","slug":"云端","link":"#云端","children":[{"level":3,"title":"腾讯云","slug":"腾讯云","link":"#腾讯云","children":[]},{"level":3,"title":"whisper","slug":"whisper","link":"#whisper","children":[]},{"level":3,"title":"incredibly-fast-whisper","slug":"incredibly-fast-whisper","link":"#incredibly-fast-whisper","children":[]},{"level":3,"title":"groq","slug":"groq","link":"#groq","children":[]}]}],"git":{"createdTime":1699197704000,"updatedTime":1729097649000,"contributors":[{"name":"lxl66566","email":"lxl66566@gmail.com","commits":7},{"name":"lxl66566","email":"18259734087@163.com","commits":4}]},"readingTime":{"minutes":2.48,"words":744},"filePathRelative":"articles/voice2text.md","localizedDate":"2023年11月5日","excerpt":"\\n","autoDesc":true}');export{y as comp,v as data};
