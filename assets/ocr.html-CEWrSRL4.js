import{_ as s,e as p,g as i,f as r,h as t,i as n,j as o,r as l,o as d}from"./app-C9kwRrPC.js";const c={};function m(h,e){const a=l("RouteLink");return d(),p("div",null,[e[6]||(e[6]=i("h1",{id:"ocr",tabindex:"-1"},[i("a",{class:"header-anchor",href:"#ocr"},[i("span",null,"OCR")])],-1)),i("p",null,[e[1]||(e[1]=t("OCR 也是生活中的一大刚需，甚至比")),n(a,{to:"/articles/voice2text.html"},{default:o(()=>e[0]||(e[0]=[t("语音转文字")])),_:1}),e[2]||(e[2]=t("更为重要。"))]),e[7]||(e[7]=r('<p>优秀的 OCR 在面对常见字体的印刷字时需要做到 100% 正确率，并且在其他恶劣条件下仍能保证一定正确率。</p><div class="hint-container tip"><p class="hint-container-title">提示</p><p><strong>付费服务</strong>不在本文考虑范围内。</p><p><em>手写识别</em> 并不是传统 OCR 的刚需，因此本文对其不作要求。</p></div><h2 id="android" tabindex="-1"><a class="header-anchor" href="#android"><span>Android</span></a></h2><p>如果你使用的是国产系统，那么 Android 端的 OCR 并不需要其他软件，大多数手机自带的相册即可胜任。</p><ul><li>MIUI（小米）：体验很好。相册打开图片的状态下长按并稍等片刻即可自由复制。</li><li>ColorOS（一加）：体验较差。只有使用相机“超级文本”模式下拍摄的照片才能 OCR。点开照片，右上角有 <em>文字识别</em> 按钮。</li></ul><h2 id="windows" tabindex="-1"><a class="header-anchor" href="#windows"><span>Windows</span></a></h2>',6)),i("p",null,[e[4]||(e[4]=t("windows 下的 OCR 我首推 ")),n(a,{to:"/farraginous/recommend_packages.html#%E6%88%AA%E5%9B%BE%E8%BD%AF%E4%BB%B6"},{default:o(()=>e[3]||(e[3]=[t("PixPin")])),_:1}),e[5]||(e[5]=t("。它其实是一个截图软件，附带了离线 OCR 功能，中文的识别准确率非常高。"))]),e[8]||(e[8]=r('<p>包含模型，软件总大小 70M 左右，我还是很满意的。</p><h2 id="linux" tabindex="-1"><a class="header-anchor" href="#linux"><span>Linux</span></a></h2><p>有个 <a href="https://github.com/dynobo/normcap" target="_blank" rel="noopener noreferrer">NormCap</a>，其本质上是基于 <code>Tesseract OCR</code> 的前端。</p><p>在 archlinux 上安装：</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">paru</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -S</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> normcap</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> tesseract-data-chi_sim</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>然后打开，右上角 <em>设置</em> 的 <em>language</em> 选择 <code>chi</code> 即可。</p><p>这个离线模型大小 41M 左右，准确率特别差，例如 PDF 扫描件 OCR。</p><p>然后我实在是忍不了了，试了一下用 wine 装 <a href="#windows">PixPin</a>，居然能用，就是没有快捷键，不过也无所谓了。</p>',8))])}const u=s(c,[["render",m],["__file","ocr.html.vue"]]),C=JSON.parse('{"path":"/articles/ocr.html","title":"OCR","lang":"zh-CN","frontmatter":{"date":"2023-12-09T00:00:00.000Z","icon":"camera-rotate","category":["推荐","评价"],"tag":["横评","移动端","桌面端"],"description":"OCR OCR 也是生活中的一大刚需，甚至比更为重要。 优秀的 OCR 在面对常见字体的印刷字时需要做到 100% 正确率，并且在其他恶劣条件下仍能保证一定正确率。 提示 付费服务不在本文考虑范围内。 手写识别 并不是传统 OCR 的刚需，因此本文对其不作要求。 Android 如果你使用的是国产系统，那么 Android 端的 OCR 并不需要其他软...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"OCR\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2023-12-09T00:00:00.000Z\\",\\"dateModified\\":\\"2024-06-10T08:35:24.000Z\\",\\"author\\":[]}"],["meta",{"property":"og:url","content":"https://absx.pages.dev/articles/ocr.html"}],["meta",{"property":"og:site_name","content":"绝对值_x 的博客"}],["meta",{"property":"og:title","content":"OCR"}],["meta",{"property":"og:description","content":"OCR OCR 也是生活中的一大刚需，甚至比更为重要。 优秀的 OCR 在面对常见字体的印刷字时需要做到 100% 正确率，并且在其他恶劣条件下仍能保证一定正确率。 提示 付费服务不在本文考虑范围内。 手写识别 并不是传统 OCR 的刚需，因此本文对其不作要求。 Android 如果你使用的是国产系统，那么 Android 端的 OCR 并不需要其他软..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-06-10T08:35:24.000Z"}],["meta",{"property":"article:tag","content":"桌面端"}],["meta",{"property":"article:tag","content":"移动端"}],["meta",{"property":"article:tag","content":"横评"}],["meta",{"property":"article:published_time","content":"2023-12-09T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2024-06-10T08:35:24.000Z"}]]},"git":{"createdTime":1702136768000,"updatedTime":1718008524000,"contributors":[{"name":"lxl66566","username":"lxl66566","email":"18259734087@163.com","commits":4,"url":"https://github.com/lxl66566"}]},"readingTime":{"minutes":1.38,"words":413},"filePathRelative":"articles/ocr.md","localizedDate":"2023年12月9日","excerpt":"\\n","autoDesc":true}');export{u as comp,C as data};
